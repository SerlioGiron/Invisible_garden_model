import os
import sys
import asyncio
import json
import re
from datetime import datetime

# Configuraci√≥n para Windows y PyTorch
if sys.platform == "win32":
    # 1. Deshabilitar completamente el file watcher
    os.environ["STREAMLIT_SERVER_ENABLE_STATIC_FILE_WATCHER"] = "false"
    
    # 2. Configurar el event loop policy
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    
    # 3. Parchear el sistema de clases de Torch
    try:
        import torch
        torch.classes.__path__ = []  # Elimina la inspecci√≥n de rutas conflictivas
    except ImportError:
        pass  # Torch no est√° instalado

import streamlit as st    
from dotenv import load_dotenv
from langchain_core.prompts import ChatPromptTemplate
from langchain_groq import ChatGroq

load_dotenv()

# Configurar claves API
groq_api_key = os.getenv("GROQ_API_KEY")
if not groq_api_key:
    st.error("No se encontr√≥ la clave API de Groq. Aseg√∫rate de configurar GROQ_API_KEY en tu archivo .env")

model = ChatGroq(groq_api_key=groq_api_key, model="llama-3.3-70b-versatile")

st.set_page_config(page_title="Analizador de Comentarios", layout="wide")

@st.cache_data
def load_tags():
    """Cargar tags desde el archivo tags.txt"""
    try:
        with open("tags.txt", "r", encoding="utf-8") as file:
            tags = [line.strip().lower() for line in file if line.strip()]
        return tags
    except FileNotFoundError:
        st.error("No se encontr√≥ el archivo tags.txt")
        return []
    except Exception as e:
        st.error(f"Error cargando tags: {str(e)}")
        return []

def is_coherent_text(text):
    """Validar si el texto es coherente (m√°s de una palabra y tiene sentido b√°sico)"""
    text = text.strip()
    
    # 1. Verificar que no est√© vac√≠o
    if not text:
        return False
    
    # 2. Verificar que tenga al menos 2 palabras
    words = text.split()
    if len(words) < 2:
        return False
    
    # 3. Verificar que no sean solo caracteres especiales o n√∫meros
    clean_text = re.sub(r'[^\w\s]', '', text)
    if len(clean_text.strip()) < 3:
        return False
    
    # 4. Verificar que no sean solo repeticiones de la misma palabra
    unique_words = set(word.lower() for word in words if word.isalpha())
    if len(unique_words) < 2:
        return False
    
    # 5. Detectar incoherencia sem√°ntica usando reglas h√≠bridas
    
    # Lista de patrones espec√≠ficamente incoherentes
    incoherent_patterns = [
        "casa azul mojado", "perro volando matem√°ticas", "mesa correr feliz",
        "computadora cantar verde", "silla bailar n√∫mero", "√°rbol escribir calor",
        "tel√©fono dormir az√∫car", "libro nadar rojo", "ventana comer fr√≠os",
        "zapato volar m√∫sica", "reloj bailar agua", "puerta correr n√∫meros"
    ]
    
    # Si es exactamente uno de estos casos, es incoherente
    if text.lower().strip() in incoherent_patterns:
        return False
    
    # Verificar patrones de incoherencia (sustantivo + verbo incongruente + adjetivo/sustantivo)
    # Ejemplo: "casa cantar azul" (objeto f√≠sico + acci√≥n incompatible + descriptor)
    if len(words) == 3:
        # Objetos f√≠sicos que no pueden realizar ciertas acciones
        objects = {'casa', 'mesa', 'silla', 'puerta', 'ventana', 'libro', 'tel√©fono', 'computadora'}
        impossible_actions = {'cantar', 'bailar', 'correr', 'volar', 'nadar', 'dormir', 'comer'}
        
        word1, word2, word3 = [w.lower() for w in words]
        
        # Si primer palabra es objeto y segunda es acci√≥n imposible
        if word1 in objects and word2 in impossible_actions:
            return False
    
    # Verificar estructura m√≠nima de oraci√≥n en espa√±ol
    structure_indicators = {
        # Art√≠culos
        'el', 'la', 'los', 'las', 'un', 'una', 'unos', 'unas',
        # Verbos auxiliares y comunes
        'es', 'est√°', 'son', 'est√°n', 'tiene', 'tienen', 'hay', 'fue', 'era',
        # Preposiciones
        'de', 'del', 'en', 'con', 'por', 'para', 'desde', 'hasta', 'sobre',
        # Pronombres y conectores
        'que', 'se', 'me', 'te', 'le', 'nos', 'les', 'mi', 'tu', 'su',
        # Adverbios y conjunciones
        'muy', 'm√°s', 'menos', 'bien', 'mal', 'no', 's√≠', 'y', 'o', 'pero',
        # Verbos de opini√≥n/estado
        'quiero', 'necesito', 'creo', 'pienso', 'siento', 'veo', 'escucho',
        'necesitamos', 'queremos', 'podemos', 'debemos'
    }
    
    text_words = set(word.lower() for word in words)
    has_structure = bool(text_words.intersection(structure_indicators))
    
    # Si no tiene indicadores estructurales, probablemente es incoherente
    if not has_structure:
        return False
    
    return True

def extract_tags_from_text(text, available_tags):
    """Extraer tags relevantes del texto - cantidad din√°mica seg√∫n longitud"""
    text_lower = text.lower()
    tag_scores = {}  # tag -> puntuaci√≥n de relevancia
    
    # Palabras del texto
    words_in_text = re.findall(r'\b\w+\b', text_lower)
    
    # Determinar cantidad m√°xima de tags seg√∫n longitud del texto
    if len(words_in_text) <= 4:  # Texto muy corto (4 palabras o menos)
        max_tags = 1
    elif len(words_in_text) <= 8:  # Texto mediano (5-8 palabras)
        max_tags = 2
    else:  # Texto largo (9+ palabras)
        max_tags = 3
    
    for tag in available_tags:
        score = 0
        matches = []  # Posiciones donde se encuentra el tag
        
        # 1. B√∫squeda exacta
        for i, word in enumerate(words_in_text):
            if word == tag:
                matches.append(i)
                score += 3  # Puntuaci√≥n alta para coincidencia exacta
        
        # 2. B√∫squeda de variaciones simples
        if not matches:  # Solo si no hubo coincidencia exacta
            for i, word in enumerate(words_in_text):
                # Plurales simples: maestro -> maestros
                if word == tag + 's' or tag == word + 's':
                    matches.append(i)
                    score += 2  # Puntuaci√≥n media para variaciones
                    break
                # Plurales con 'es': clase -> clases
                elif word == tag + 'es' or tag == word + 'es':
                    matches.append(i)
                    score += 2
                    break
        
        # Si encontramos el tag, calcular puntuaci√≥n final
        if matches:
            # Bonus por longitud del tag (tags m√°s espec√≠ficos son m√°s relevantes)
            score += len(tag) * 0.1
            
            # Bonus por posici√≥n temprana en el texto
            first_position = min(matches)
            position_bonus = max(0, 5 - first_position)  # M√°s puntos si aparece al principio
            score += position_bonus
            
            # Bonus por frecuencia
            frequency_bonus = len(matches) * 0.5
            score += frequency_bonus
            
            tag_scores[tag] = score
    
    # Ordenar por relevancia (mayor puntuaci√≥n primero) y tomar seg√∫n longitud del texto
    sorted_tags = sorted(tag_scores.items(), key=lambda x: x[1], reverse=True)
    most_relevant_tags = [tag for tag, score in sorted_tags[:max_tags]]
    
    return most_relevant_tags

def categorize_comment(comment):
    """Categorizar el comentario usando LLM - Soporta espa√±ol e ingl√©s"""
    template = """
    Analyze the following comment and categorize it EXACTLY into one of these four categories:
    - "Sugerencia": If the comment proposes improvements, ideas, changes or constructive recommendations
    - "Opinion": If the comment expresses a neutral or positive personal opinion, experiences without being offensive
    - "HateSpeech": If the comment contains offensive language, discrimination, threats, insults, very negative criticism, or very negative feelings towards people (e.g.: "the teacher is bad", "I hate...", "it's terrible", etc.)
    - "Vida universitaria": If the comment specifically refers to experiences, situations, activities or aspects of university, academic or student life that do not fit into the other categories

    Important rules:
    1. Respond ONLY with one of these four words: "Sugerencia", "Opinion", "HateSpeech", or "Vida universitaria"
    2. Do not add additional explanations
    3. Negative comments about people (teachers, classmates, etc.) go in "HateSpeech"
    4. Comments about classes, university, studies, campus, etc. go in "Vida universitaria"
    5. If in doubt, prioritize in this order: HateSpeech > Vida universitaria > Sugerencia > Opinion
    6. THE COMMENT CAN BE IN SPANISH OR ENGLISH - Detect the language and analyze accordingly

    Examples (Spanish):
    - "El maestro es malo" ‚Üí HateSpeech
    - "La clase de matem√°ticas es dif√≠cil" ‚Üí Vida universitaria
    - "Deber√≠an mejorar la cafeter√≠a" ‚Üí Sugerencia
    - "Me gusta estudiar" ‚Üí Opinion
    
    Examples (English):
    - "The teacher is terrible" ‚Üí HateSpeech
    - "Math class is challenging" ‚Üí Vida universitaria
    - "They should improve the cafeteria" ‚Üí Sugerencia
    - "I enjoy studying" ‚Üí Opinion

    Comment: "{comment}"
    
    Category:
    """
    
    prompt = ChatPromptTemplate.from_template(template)
    chain = prompt | model
    
    try:
        response = ""
        for chunk in chain.stream({"comment": comment}):
            response += chunk.content
        
        # Limpiar la respuesta y validar
        category = response.strip()
        valid_categories = ["Sugerencia", "Opinion", "HateSpeech", "Vida universitaria"]
        
        if category in valid_categories:
            return category
        else:
            # Si la respuesta no es v√°lida, intentar extraer una categor√≠a v√°lida
            for valid_cat in valid_categories:
                if valid_cat.lower() in category.lower():
                    return valid_cat
            # Si no se encuentra ninguna, retornar Opinion por defecto
            return "Opinion"
            
    except Exception as e:
        st.error(f"Error categorizando comentario: {str(e)}")
        return "Opinion"  # Categor√≠a por defecto en caso de error

def formalize_hate_speech(comment):
    """Convertir comentario ofensivo a lenguaje formal y apropiado - Soporta espa√±ol e ingl√©s"""
    template = """
    You are a language moderator. The following comment contains offensive language. Convert it to a formal, respectful and constructive comment that expresses the same idea but in a manner appropriate for an academic or professional environment.

    CRITICAL RULES:
    1. Remove all offensive words, vulgarities or insults
    2. Maintain the essence of the message but in a constructive tone
    3. Use formal and respectful language
    4. If it's a complaint, convert it to constructive feedback
    5. Maximum 2-3 lines
    6. Respond ONLY with the formalized text, without additional explanations
    7. **MANDATORY**: If the original comment is in ENGLISH, respond in ENGLISH. If it's in SPANISH, respond in SPANISH. NEVER change the language.

    Examples:
    - Original (English): "This teacher sucks" ‚Üí Formalized (English): "I believe the teaching methodology could be improved"
    - Original (Spanish): "Este profesor es horrible" ‚Üí Formalized (Spanish): "Considero que la metodolog√≠a de ense√±anza podr√≠a mejorar"

    Original comment: "{comment}"

    Formalized comment (in the SAME language as the original):
    """
    
    prompt = ChatPromptTemplate.from_template(template)
    chain = prompt | model
    
    try:
        response = ""
        for chunk in chain.stream({"comment": comment}):
            response += chunk.content
        
        # Limpiar la respuesta
        formalized = response.strip()
        
        # Quitar comillas si las hay
        if formalized.startswith('"') and formalized.endswith('"'):
            formalized = formalized[1:-1]
        elif formalized.startswith("'") and formalized.endswith("'"):
            formalized = formalized[1:-1]
        
        # Quitar cualquier comilla doble o simple sobrante
        formalized = formalized.replace('""', '').replace("''", '')
        
        # Si la respuesta est√° vac√≠a o muy corta, usar una versi√≥n gen√©rica
        if len(formalized) < 10:
            formalized = "Comentario convertido a lenguaje apropiado por contener contenido ofensivo."
        
        return formalized
        
    except Exception as e:
        st.error(f"Error formalizando comentario: {str(e)}")
        return "Comentario modificado por contener contenido inapropiado."

def save_to_json(data, filename="comentarios_analizados.json"):
    """Guardar datos en archivo JSON"""
    try:
        # Cargar datos existentes si el archivo existe
        if os.path.exists(filename):
            with open(filename, "r", encoding="utf-8") as file:
                existing_data = json.load(file)
        else:
            existing_data = []
        
        # Agregar nuevo an√°lisis
        existing_data.append(data)
        
        # Guardar datos actualizados
        with open(filename, "w", encoding="utf-8") as file:
            json.dump(existing_data, file, ensure_ascii=False, indent=2)
        
        return True
    except Exception as e:
        st.error(f"Error guardando en JSON: {str(e)}")
        return False

def load_analysis_history():
    """Cargar historial de an√°lisis desde JSON"""
    try:
        if os.path.exists("comentarios_analizados.json"):
            with open("comentarios_analizados.json", "r", encoding="utf-8") as file:
                return json.load(file)
        return []
    except Exception as e:
        st.error(f"Error cargando historial: {str(e)}")
        return []

def display_statistics(history):
    """Mostrar estad√≠sticas del an√°lisis"""
    if not history:
        return
    
    # Contar categor√≠as
    categories = [item["categoria"] for item in history]
    category_counts = {
        "Sugerencia": categories.count("Sugerencia"),
        "Opinion": categories.count("Opinion"),
        "HateSpeech": categories.count("HateSpeech"),
        "Vida universitaria": categories.count("Vida universitaria")
    }
    
    # Mostrar estad√≠sticas
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Sugerencias", category_counts["Sugerencia"])
    with col2:
        st.metric("Opiniones", category_counts["Opinion"])
    with col3:
        st.metric("Hate Speech", category_counts["HateSpeech"])
    with col4:
        st.metric("Vida Universitaria", category_counts["Vida universitaria"])
    
    # Tags m√°s comunes
    all_tags = []
    for item in history:
        all_tags.extend(item["tags"])
    
    if all_tags:
        from collections import Counter
        tag_counts = Counter(all_tags)
        st.subheader("Tags m√°s comunes:")
        for tag, count in tag_counts.most_common(10):
            st.write(f"‚Ä¢ {tag}: {count} veces")

def main():
    st.title("üéì Analizador de Comentarios Universitarios")
    st.markdown("### Detecta autom√°ticamente si un comentario es una Sugerencia, Opini√≥n, Hate Speech o sobre Vida Universitaria")
    
    # Cargar tags disponibles
    available_tags = load_tags()
    if not available_tags:
        st.warning("No se pudieron cargar los tags. El an√°lisis continuar√° sin detecci√≥n de tags.")
    
    # Sidebar para configuraci√≥n
    with st.sidebar:
        st.header("üìä Configuraci√≥n")
        
        # Mostrar estad√≠sticas
        history = load_analysis_history()
        st.subheader(f"An√°lisis realizados: {len(history)}")
        
        if history:
            display_statistics(history)
        
        # Opci√≥n para descargar historial
        if st.button("üì• Descargar Historial JSON"):
            if history:
                json_str = json.dumps(history, ensure_ascii=False, indent=2)
                st.download_button(
                    label="Descargar comentarios_analizados.json",
                    data=json_str,
                    file_name="comentarios_analizados.json",
                    mime="application/json"
                )
        
        # Opci√≥n para limpiar historial
        if st.button("üóëÔ∏è Limpiar Historial"):
            if os.path.exists("comentarios_analizados.json"):
                os.remove("comentarios_analizados.json")
                st.success("Historial limpiado")
                st.rerun()
    
    # Input principal
    st.subheader("üí¨ Ingresa un comentario para analizar:")
    
    # Inicializar session state para el comentario y el estado de formalizaci√≥n
    if "comment_text" not in st.session_state:
        st.session_state.comment_text = ""
    if "show_formalized_message" not in st.session_state:
        st.session_state.show_formalized_message = False
    if "last_comment" not in st.session_state:
        st.session_state.last_comment = ""
    if "is_formalized_comment" not in st.session_state:
        st.session_state.is_formalized_comment = False
    
    # Mostrar mensaje si el comentario fue formalizado
    if st.session_state.show_formalized_message:
        st.warning("‚ö†Ô∏è **Versi√≥n formalizada ya que se consider√≥ ofensiva su mensaje anterior:**")
    
    comment_input = st.text_area(
        "Comentario:",
        value=st.session_state.comment_text,
        placeholder="Escribe aqu√≠ el comentario que quieres analizar...",
        height=100,
        key="comment_input"
    )
    
    # Si el usuario cambi√≥ el texto, ocultar el mensaje de formalizaci√≥n
    if comment_input != st.session_state.last_comment and st.session_state.show_formalized_message:
        if comment_input != st.session_state.comment_text:  # Solo si realmente edit√≥
            st.session_state.show_formalized_message = False
    
    st.session_state.last_comment = comment_input
    
    col1, col2 = st.columns([1, 4])
    
    with col1:
        analyze_button = st.button("üîç Analizar Comentario", type="primary")
    
    if analyze_button and comment_input.strip():
        # Validar que el texto sea coherente
        if not is_coherent_text(comment_input):
            st.error("‚ö†Ô∏è Se tiene que escribir algo coherente")
        else:
            with st.spinner("Analizando comentario..."):
                # 1. Categorizar comentario original
                original_category = categorize_comment(comment_input)
                
                # 2. Si es HateSpeech y NO ha sido formalizado a√∫n, formalizarlo
                if original_category == "HateSpeech" and not st.session_state.is_formalized_comment:
                    final_comment = formalize_hate_speech(comment_input)
                    # Actualizar el texto en el session state para que se refleje en el input
                    st.session_state.comment_text = final_comment
                    st.session_state.show_formalized_message = True
                    st.session_state.is_formalized_comment = True
                    st.rerun()  # Recargar para mostrar el texto actualizado
                
                # 3. Si llegamos aqu√≠, procesar normalmente (incluso si es HateSpeech formalizado)
                final_comment = comment_input
                final_category = original_category
                
                # Si es un comentario que fue formalizado, mantener la categor√≠a como HateSpeech
                if st.session_state.is_formalized_comment and st.session_state.show_formalized_message:
                    final_category = "HateSpeech"
                    st.session_state.is_formalized_comment = False  # Reset para la pr√≥xima vez
            
            # 4. Extraer tags del comentario final
            extracted_tags = extract_tags_from_text(final_comment, available_tags)
            
            # 5. Crear estructura de datos
            analysis_data = {
                "timestamp": datetime.now().isoformat(),
                "comentario": final_comment,
                "categoria": final_category,
                "tags": extracted_tags
            }
            
            # 6. Guardar en JSON
            if save_to_json(analysis_data):
                st.success("‚úÖ An√°lisis guardado exitosamente")
            
            # 7. Mostrar resultados
            st.divider()
            st.subheader("üìã Resultados del An√°lisis:")
            
            # Mostrar categor√≠a con color
            category_colors = {
                "Sugerencia": "üü¢",
                "Opinion": "üîµ", 
                "HateSpeech": "üî¥",
                "Vida universitaria": "üü°"
            }
            
            st.markdown(f"**Categor√≠a:** {category_colors.get(final_category, '‚ö™')} **{final_category}**")
            
            # Mostrar tags
            if extracted_tags:
                st.markdown(f"**Tags encontrados:** {', '.join(extracted_tags)}")
            else:
                st.markdown("**Tags encontrados:** Ninguno")
            
            # Mostrar JSON generado
            with st.expander("Ver JSON generado"):
                st.json(analysis_data)
    
    elif analyze_button:
        st.warning("‚ö†Ô∏è Se tiene que escribir algo coherente")
    
    # Mostrar historial reciente
    if history:
        st.divider()
        st.subheader("üìö Historial Reciente (√∫ltimos 5 an√°lisis)")
        
        for item in reversed(history[-5:]):  # Mostrar los √∫ltimos 5
            # Manejar tanto estructura antigua como nueva
            comentario_display = item.get('comentario', item.get('comentario_final', 'Sin comentario'))
            comentario_preview = comentario_display[:50] + "..." if len(comentario_display) > 50 else comentario_display
            
            with st.expander(f"{item['categoria']} - {comentario_preview}"):
                st.write(f"**Comentario:** {comentario_display}")
                st.write(f"**Categor√≠a:** {item['categoria']}")
                st.write(f"**Tags:** {', '.join(item['tags']) if item['tags'] else 'Ninguno'}")
                st.write(f"**Fecha:** {item['timestamp']}")
                
                st.write(f"**Categor√≠a:** {item['categoria']}")
                st.write(f"**Tags:** {', '.join(item['tags']) if item['tags'] else 'Ninguno'}")
                st.write(f"**Fecha:** {item['timestamp']}")

if __name__ == "__main__":
    main()
